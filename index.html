<!DOCTYPE html>
<html lang="en">
<head>
  <style>
    div {
      max-width: 1000px;
      min-width: 600px;
    }
    table, th, td {
      border: 1px solid black;
    }
  </style>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Document</title>
</head>
<body>
  <center>
  <h1> Blind Estimation of Audio Processing Graph  </h1>
    Sungho Lee, Jaehyun Park, Seungryeol Paik, and Kyogu Lee <br>
    Department of Intelligence and Information, Seoul National University, Seoul, Republic of Korea <br>
    <br>
    <b>Abstract</b>
    
    Musicians and audio engineers sculpt and transform their sounds by connecting multiple processors, forming an \emph{audio processing graph}. 
However, most deep-learning methods overlook this real-world practice and assume fixed graph settings.
To bridge this gap, we develop a system that reconstructs the entire graph from a given reference audio. 
We first generate a realistic graph-reference pair dataset and train a simple blind estimation system composed of a convolutional reference encoder and a transformer-based graph decoder.
We apply our framework to singing voice effects and drum mixing estimation tasks; evaluation results show that our method can reconstruct complex signal routings, including multi-band processing and sidechaining, and rendered signal from the estimated graphs processes is perceptually similar to the given reference.

  </center>
<br>
Samples: TBA
<br>
Codes: TBA
</body>
</html>
